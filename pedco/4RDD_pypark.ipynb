{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea3dd051-869e-4e87-9353-d4286425a463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.host', '192.168.1.42'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/usuarioFAI/ejemplosPython/spark-warehouse'),\n",
       " ('spark.app.id', 'app-20210512232509-0004'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.driver.port', '42195'),\n",
       " ('spark.executor.memory', '1g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.startTime', '1620872706374'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.instances', '1'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'spark://bigdata-srv.fi.uncoma.edu.ar:7077'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.name', 'probandospark'),\n",
       " ('spark.executor.memoryOverhead', '1g')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#importo la libreria\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#abro una sesion con un nombre\n",
    "\n",
    "#hay que tener cuidado que los workers de spark tengan la cantidad de Mb para ejecutar\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".config(\"spark.submit.deployMode\", \"client\")\\\n",
    ".config(\"spark.executor.instances\", \"1\")\\\n",
    ".config(\"spark.executor.memory\", \"1g\")\\\n",
    ".config(\"spark.driver.memory\", \"1g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"1g\")\\\n",
    ".appName(\"probandospark4rdd\")\\\n",
    ".master(\"spark://bigdata-srv.fi.uncoma.edu.ar:7077\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.sparkContext._conf.getAll()  # ver la configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776c35d6-809a-4fbd-b71e-74f27d8c1f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "def pruebaRDD():\n",
    "    #spark = SparkSession.builder.appName('ejemplo-de-rdd').getOrCreate()\n",
    "    data = [1, 2, 3, 4, 5]\n",
    "    distData = spark.sparkContext.parallelize(data)\n",
    "    distDataMap=distData.map(lambda s: s+1)\n",
    "    print(distDataMap.take(5))\n",
    "    print(distDataMap.reduce(lambda a , b: a + b))\n",
    "\n",
    "pruebaRDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90d2a25-5dc9-4cf4-8570-671e2510f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cierro la sesión\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dccd73-f0ec-408e-9448-c521b3f2b7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
