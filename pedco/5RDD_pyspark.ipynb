{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896adef6-f9b5-4831-9503-bcacc92a848e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.host', '192.168.1.42'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/usuarioFAI/ejemplosPython/spark-warehouse'),\n",
       " ('spark.app.startTime', '1620874057761'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.executor.memory', '1g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.app.name', 'probandospark5rdd'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.app.id', 'app-20210512234739-0005'),\n",
       " ('spark.executor.instances', '1'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'spark://bigdata-srv.fi.uncoma.edu.ar:7077'),\n",
       " ('spark.driver.port', '36480'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.executor.memoryOverhead', '1g')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#importo la libreria\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#abro una sesion con un nombre\n",
    "\n",
    "#hay que tener cuidado que los workers de spark tengan la cantidad de Mb para ejecutar\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".config(\"spark.submit.deployMode\", \"client\")\\\n",
    ".config(\"spark.executor.instances\", \"1\")\\\n",
    ".config(\"spark.executor.memory\", \"1g\")\\\n",
    ".config(\"spark.driver.memory\", \"1g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"1g\")\\\n",
    ".appName(\"probandospark5rdd\")\\\n",
    ".master(\"spark://bigdata-srv.fi.uncoma.edu.ar:7077\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.sparkContext._conf.getAll()  # ver la configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54249c12-f8f0-47e4-8118-40167cdef593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad total de letras de la fuente es: 32364\n"
     ]
    }
   ],
   "source": [
    "def pruebaRDDdesdeHDFS():  \n",
    "    distFile = spark.sparkContext.textFile('hdfs://127.0.0.1:9000/cursoFAI/nba.csv')\n",
    "    #len(s) cuenta la longitud de un string s\n",
    "    lineLengths = distFile.map(lambda s: len(s))\n",
    "    totalLength =lineLengths.reduce(lambda a, b: a + b)\n",
    "    print(\"La cantidad total de letras de la fuente es:\", totalLength)    \n",
    "        \n",
    "pruebaRDDdesdeHDFS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd70d26-45bb-4ced-9122-b6c8cbcd802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cierro la sesión\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
