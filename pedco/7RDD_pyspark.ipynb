{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "952eaf19-ed95-4cc5-85d4-e1fd3f578b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'probandospark7rdd'),\n",
       " ('spark.app.id', 'app-20210513000313-0007'),\n",
       " ('spark.driver.host', '192.168.1.42'),\n",
       " ('spark.driver.port', '35343'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/usuarioFAI/ejemplosPython/spark-warehouse'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.startTime', '1620874990191'),\n",
       " ('spark.driver.memory', '1g'),\n",
       " ('spark.executor.memory', '1g'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.executor.instances', '1'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.master', 'spark://bigdata-srv.fi.uncoma.edu.ar:7077'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.executor.memoryOverhead', '1g')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#from operator import max\n",
    "\n",
    "\n",
    "#abro una sesion con un nombre\n",
    "#hay que tener cuidado que los workers de spark tengan la cantidad de Mb para ejecutar\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".config(\"spark.submit.deployMode\", \"client\")\\\n",
    ".config(\"spark.executor.instances\", \"1\")\\\n",
    ".config(\"spark.executor.memory\", \"1g\")\\\n",
    ".config(\"spark.driver.memory\", \"1g\")\\\n",
    ".config(\"spark.executor.memoryOverhead\", \"1g\")\\\n",
    ".appName(\"probandospark7rdd\")\\\n",
    ".master(\"spark://bigdata-srv.fi.uncoma.edu.ar:7077\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "spark.sparkContext._conf.getAll()  # ver la configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "354ade2e-c161-4a00-a16a-ea5a7d0f97e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de letras por palabra [(6, 'Gaston'), (7, 'Martina'), (9, 'Adalberto'), (8, 'Carolina'), (8, 'Agustina'), (3, 'Sol'), (5, 'Juana')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(3, 'Sol'),\n",
       " (5, 'Juana'),\n",
       " (6, 'Gaston'),\n",
       " (7, 'Martina'),\n",
       " (8, 'Carolina'),\n",
       " (8, 'Agustina'),\n",
       " (9, 'Adalberto')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "distData = spark.sparkContext.parallelize (\n",
    "   [\"Gaston\", \n",
    "   \"Martina\", \n",
    "   \"Adalberto\", \n",
    "   \"Carolina\", \n",
    "   \"Agustina\",\n",
    "    \"Sol\",\n",
    "   \"Juana\"])\n",
    "\n",
    "\n",
    "long_map = distData.map(lambda x: (len(x),x))\n",
    "coleccion = long_map.collect()\n",
    "print (\"Cantidad de letras por palabra\",coleccion)\n",
    "long_map.sortByKey(ascending=True).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e3591b0-9e95-4586-af09-492b9bcbfaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de letras por palabra [6, 7, 9, 8, 8, 3, 5]\n",
      "max 9\n",
      "min 3\n",
      "Cantidad de letras por palabra [('Gaston', 6), ('Martina', 7), ('Adalberto', 9), ('Carolina', 8), ('Agustina', 8), ('Sol', 3), ('Juana', 5)]\n",
      "max ('Sol', 3)\n",
      "min ('Adalberto', 9)\n"
     ]
    }
   ],
   "source": [
    "#Un operador lambda puede tener muchos argumentos y devuelve un objeto de función que se puede asignar a cualquier variable. Se pasan como parámetros a funciones que esperan objetos de función como parámetros tales como map, reduce y filter.\n",
    "#La funciòn map ejecuta el objeto de función para cada elemento de la secuencia y devuelve una lista de los elementos modificados por el objeto de función.\n",
    "long_map = distData.map(lambda x: (len(x)))\n",
    "coleccion = long_map.collect()\n",
    "print (\"Cantidad de letras por palabra\",coleccion)\n",
    "#La función reduce aplica continuamente la funciòn a la secuencia devolviendo un solo valor \n",
    "print (\"max\", long_map.reduce(lambda a,b: a if (a > b) else b))\n",
    "print ( \"min\", long_map.reduce(lambda a,b: a if (a < b) else b))\n",
    "\n",
    "long_map = distData.map(lambda x: (x,len(x)))\n",
    "coleccion = long_map.collect()\n",
    "print (\"Cantidad de letras por palabra\",coleccion)\n",
    "#La función reduce aplica continuamente la funciòn a la secuencia devolviendo un solo valor \n",
    "print (\"max\", long_map.reduce(lambda a,b: a if (a > b) else b))\n",
    "print ( \"min\", long_map.reduce(lambda a,b: a if (a < b) else b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77510fb-d579-4d2a-a1ca-f0473dd1328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cierro la sesión\n",
    "spark.sparkContext.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334e6eb-3835-4c1d-9346-411db55552e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
